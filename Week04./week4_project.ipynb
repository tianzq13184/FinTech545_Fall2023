{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "For problem 1, we use each of the 3 models of returns to generate the expected price with r_t ~ N(0, sigma^2). Then we calculate the mean and standard deviation of each of the  prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def price_generator(p_t0, sigma, n, method = \"Classical Brownian Motion\"):\n",
    "#     price = np.zeros(n)\n",
    "#     price[0] = p_t0\n",
    "#     returns = np.random.normal(0, sigma, size = n)\n",
    "#     if(method.upper() == \"CLASSICAL BROWNIAN MOTION\"):\n",
    "#         for i in range(1, n):\n",
    "#             price[i] = price[i - 1] + returns[i]\n",
    "#     elif(method.upper() == \"ARITHMETIC RETURN SYSTEM\"):\n",
    "#         for i in range(1, n):\n",
    "#             price[i] = price[i - 1] * (returns[i] + 1)\n",
    "#     else:\n",
    "#         for i in range(1, n):\n",
    "#             price[i] = price[i - 1] *  math.exp(returns[i])\n",
    "#     return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_generator(p_t0, sigma, t, n, method = \"Classical Brownian Motion\"):\n",
    "    price_t = np.zeros(n)\n",
    "    if(method.upper() == \"CLASSICAL BROWNIAN MOTION\"):\n",
    "        for i in range(0, n):\n",
    "            price_t[i] = p_t0\n",
    "            returns = np.random.normal(0, sigma, size = t)\n",
    "            for j in range(1, t):\n",
    "                price_t[i] = price_t[i] + returns[j]\n",
    "    elif(method.upper() == \"ARITHMETIC RETURN SYSTEM\"):\n",
    "        for i in range(0, n):\n",
    "            price_t[i] = p_t0\n",
    "            returns = np.random.normal(0, sigma, size = t)\n",
    "            for j in range(1, t):\n",
    "                price_t[i] = price_t[i] * (returns[j] + 1)\n",
    "    else:\n",
    "        for i in range(0, n):\n",
    "            price_t[i] = p_t0\n",
    "            returns = np.random.normal(0, sigma, size = t)\n",
    "            for j in range(1, t):\n",
    "                price_t[i] = price_t[i] *  math.exp(returns[j])\n",
    "    return price_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_analyser(price, method):\n",
    "    mean = price.mean()\n",
    "    standard_deviation = price.std()\n",
    "    print(\"Mean of \" + method + \"is\", f\"{mean:.3f}\")\n",
    "    print(\"Standard deviation of \" + method + \" is\", f\"{standard_deviation:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Classical Brownian Motionis 100.001\n",
      "Standard deviation of Classical Brownian Motion is 0.302\n"
     ]
    }
   ],
   "source": [
    "method = \"Classical Brownian Motion\"\n",
    "classical_brownian_motion_price = price_generator(100, 0.1, 10, 10000, method)\n",
    "price_analyser(classical_brownian_motion_price, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Arithmetic Return Systemis 100.108\n",
      "Standard deviation of Arithmetic Return System is 30.657\n"
     ]
    }
   ],
   "source": [
    "method = \"Arithmetic Return System\"\n",
    "classical_brownian_motion_price = price_generator(100, 0.1, 10, 100000, method)\n",
    "price_analyser(classical_brownian_motion_price, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Log Returnis 104.679\n",
      "Standard deviation of Log Return is 32.136\n"
     ]
    }
   ],
   "source": [
    "method = \"Log Return\"\n",
    "classical_brownian_motion_price = price_generator(100, 0.1, 10, 100000, method)\n",
    "price_analyser(classical_brownian_motion_price, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "* Implement the return_calculate() function with all of the three ways to calculation return\n",
    "* Calculate the arithmetic returns of DailyPrice.csv and remove the mean from META\n",
    "* Calculate the VaR\n",
    "    * Using a nomal distribution\n",
    "    * Using a normal distribution with an Exponentially Weighted variance(lambda = 0.94)\n",
    "    * Using a MLE fitted T distribution\n",
    "    * Using a fitted AR(1) model\n",
    "    * Using a Historic Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_calculate(prices, method=\"DISCRETE\", dateColumn=\"Date\"):\n",
    "    vars_ = prices.columns\n",
    "    nVars = len(vars_)\n",
    "    vars_ = [var for var in vars_ if var != dateColumn]\n",
    "    if nVars == len(vars_):\n",
    "        raise ValueError(f\"dateColumn: {dateColumn} not in DataFrame: {vars_}\")\n",
    "    nVars = nVars - 1\n",
    "    p = prices[vars_].to_numpy()\n",
    "    n, m = p.shape\n",
    "    p2 = np.empty((n-1, m))\n",
    "    if method.upper() == \"DISCRETE\" or method.upper() == \"LOG\":\n",
    "    # Calculate returns\n",
    "        for i in range(n - 1):\n",
    "            for j in range(m):\n",
    "                p2[i, j] = p[i + 1, j] / p[i, j]\n",
    "        \n",
    "        if method.upper() == \"DISCRETE\":\n",
    "            p2 = p2 - 1.0\n",
    "        else:\n",
    "            p2 = np.log(p2)\n",
    "    elif method.upper() == \"CLASSIC\":\n",
    "        for i in range(n - 1):\n",
    "            for j in range(m):\n",
    "                p2[i, j] = p[i + 1, j] - p[i, j]\n",
    "    else:\n",
    "        raise ValueError(f\"method: {method} must be in ('LOG', 'DISCRETE', 'CLASSIC')\")\n",
    "    dates = prices[dateColumn].iloc[1:n].to_numpy()\n",
    "    out = pd.DataFrame({dateColumn: dates})\n",
    "    for i in range(nVars):\n",
    "        out[vars_[i]] = p2[:, i]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/14/qnbmw8kx46x2ncgblvbvxh1m0000gn/T/ipykernel_21142/1937632565.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[vars_[i]] = p2[:, i]\n",
      "/var/folders/14/qnbmw8kx46x2ncgblvbvxh1m0000gn/T/ipykernel_21142/1937632565.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[vars_[i]] = p2[:, i]\n"
     ]
    }
   ],
   "source": [
    "daily_prices = pd.read_csv(\"DailyPrices.csv\")\n",
    "daily_returns = return_calculate(daily_prices, method = \"DISCRETE\",dateColumn=\"Date\")\n",
    "# daily_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_return = daily_returns['META'].values\n",
    "meta_return_mean = meta_return.mean()\n",
    "normalize_meta_return =  meta_return - meta_return_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaR for Normal Distribution model is 0.05451621865393625\n"
     ]
    }
   ],
   "source": [
    "sigma = normalize_meta_return.std()\n",
    "normal_distribution_model = np.random.normal(0, sigma , 10000)\n",
    "VaR_normal_distribution = -np.quantile(normal_distribution_model, alpha)\n",
    "\n",
    "print(\"VaR for Normal Distribution model is\", VaR_normal_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal Distribution with Exponentially Weighted variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaR for normal distribution with exponentially weighted variance is: 0.029777311974946645\n"
     ]
    }
   ],
   "source": [
    "l = 0.94\n",
    "total_weight = 0\n",
    "length = len(normalize_meta_return)\n",
    "weights = np.zeros(length)\n",
    "for i in range(length):\n",
    "    weights[i] = (1 - l) * l ** (length - i - 1)\n",
    "    total_weight += weights[i]\n",
    "for i in range(length):\n",
    "    weights[i] = weights[i] / total_weight\n",
    "\n",
    "sigma_ew = np.sqrt((normalize_meta_return * weights).T @ normalize_meta_return)\n",
    "nomal_distribution_with_exponentially_weighted_variance_model = np.random.normal(0, sigma_ew, 10000)\n",
    "VaR_ew = -np.quantile(nomal_distribution_with_exponentially_weighted_variance_model, alpha)\n",
    "\n",
    "print(\"VaR for normal distribution with exponentially weighted variance is:\", VaR_ew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLE fitted T distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_likelihood(params, data):\n",
    "    df, loc, scale = params\n",
    "    log_likelihood = np.sum(stats.t.logpdf(data, df=df, loc=loc, scale=scale))\n",
    "    return -log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaR for MLE fitted T distribution is: 0.044348003552887996\n"
     ]
    }
   ],
   "source": [
    "initial_params = [3, 0, 1]\n",
    "result = minimize(neg_log_likelihood, initial_params, args=normalize_meta_return, method='Nelder-Mead')\n",
    "stimated_df, estimated_loc, estimated_scale = result.x\n",
    "MLE_fitted_T_model = stats.t.rvs(df=stimated_df, loc=estimated_loc, scale=estimated_scale, size=10000)\n",
    "VaR_MLE = -np.quantile(MLE_fitted_T_model, alpha)\n",
    "print(\"VaR for MLE fitted T distribution is:\", VaR_MLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AR（1）Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaR for AR(1) model is: 0.0013821452738234984\n"
     ]
    }
   ],
   "source": [
    "model = sm.tsa.ARIMA(normalize_meta_return, order=(1, 0, 0))\n",
    "results = model.fit().params\n",
    "n = 10000\n",
    "esim = np.random.normal(0,results[2],n)\n",
    "AR1_model = np.zeros(n)\n",
    "for i in range(n):\n",
    "    AR1_model[i]=results[0] + normalize_meta_return[-1] * results[1] + esim[i]\n",
    "VaR_AR1 = -np.quantile(AR1_model,alpha)\n",
    "print(\"VaR for AR(1) model is:\", VaR_AR1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAR for Historic Simulation is: 0.04202773934104901\n"
     ]
    }
   ],
   "source": [
    "# Calculate VaR using historic simulation\n",
    "historic_model = np.random.choice(normalize_meta_return,n)\n",
    "VaR_historic = -np.quantile(historic_model, alpha)\n",
    "\n",
    "print(\"VAR for Historic Simulation is: {}\".format(VaR_historic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = pd.read_csv(\"portfolio.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_calculate_1(prices, method=\"DISCRETE\", dateColumn=\"Date\"):\n",
    "    vars_ = prices.columns\n",
    "    nVars = len(vars_)\n",
    "    vars_ = [var for var in vars_ if var != dateColumn]\n",
    "    if nVars == len(vars_):\n",
    "        raise ValueError(f\"dateColumn: {dateColumn} not in DataFrame: {vars_}\")\n",
    "    nVars = nVars - 1\n",
    "    p = prices[vars_].to_numpy()\n",
    "    n, m = p.shape\n",
    "    p2 = np.empty((n-1, m))\n",
    "    for i in range(n-1):\n",
    "        for j in range(m):\n",
    "            p2[i, j] = p[i+1, j] / p[i, j]\n",
    "    if method.upper() == \"DISCRETE\":\n",
    "        p2 = p2 - 1.0\n",
    "    elif method.upper() == \"LOG\":\n",
    "        p2 = np.log(p2)\n",
    "    else:\n",
    "        raise ValueError(f\"method: {method} must be in (\\\"LOG\\\",\\\"DISCRETE\\\")\")\n",
    "    dates = prices[dateColumn].iloc[1:n].to_numpy()\n",
    "    out = pd.DataFrame({dateColumn: dates})\n",
    "    for i in range(nVars):\n",
    "        out[vars_[i]] = p2[:, i]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_portfolio_price(portfolio, prices, portfolio_name, Delta=False):\n",
    "    if portfolio_name == \"All\":\n",
    "        assets = portfolio.drop('Portfolio',axis=1)\n",
    "        assets = assets.groupby([\"Stock\"], as_index=False)[\"Holding\"].sum()\n",
    "    else:\n",
    "        assets = portfolio[portfolio[\"Portfolio\"] == portfolio_name]     \n",
    "    stock_codes = list(assets[\"Stock\"])\n",
    "    assets_prices = pd.concat([prices[\"Date\"], prices[stock_codes]], axis=1) \n",
    "    # print(assets_prices)\n",
    "    current_price = np.dot(prices[assets[\"Stock\"]].tail(1), assets[\"Holding\"])\n",
    "    holdings = assets[\"Holding\"]   \n",
    "    if Delta == True:\n",
    "        asset_values = assets[\"Holding\"].values.reshape(-1, 1) * prices[assets[\"Stock\"]].tail(1).T.values\n",
    "        delta = asset_values / current_price       \n",
    "        return current_price, assets_prices, delta   \n",
    "    return current_price, assets_prices, holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_weighted_cov(returns, lambda_=0.97):\n",
    "    returns = returns.values\n",
    "    mean_return = np.mean(returns, axis=0)\n",
    "    normalized_returns = returns - mean_return\n",
    "\n",
    "    n_timesteps = normalized_returns.shape[0]\n",
    "    cov = np.cov(returns, rowvar=False)\n",
    "\n",
    "    for t in range(1, n_timesteps):\n",
    "        cov = lambda_ * cov + (1 - lambda_) * np.outer(normalized_returns[t], normalized_returns[t])\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate with Delta Normal\n",
    "def calculate_delta_var(portfolio, prices, alpha=0.05, lambda_=0.94, portfolio_name=\"All\"):\n",
    "    current_price, assets_prices, delta = get_portfolio_price(portfolio, prices, portfolio_name, Delta=True)\n",
    "    returns = return_calculate(assets_prices, dateColumn=\"Date\").drop('Date', axis=1)\n",
    "    assets_cov = exp_weighted_cov(returns, lambda_)\n",
    "    p_sig = np.sqrt(np.transpose(delta) @ assets_cov @ delta)\n",
    "    var_delta = -current_price * stats.norm.ppf(alpha) * p_sig\n",
    "    return current_price[0], var_delta[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate with historical simulation\n",
    "def calculate_historic_var(portfolio, prices, alpha=0.05,n_simulation=1000, portfolio_name=\"All\"):\n",
    "    current_price, assets_prices, holdings = get_portfolio_price(portfolio, prices, portfolio_name)  \n",
    "    returns = return_calculate(assets_prices, dateColumn=\"Date\").drop(\"Date\", axis=1)  \n",
    "    assets_prices = assets_prices.drop('Date',axis=1)\n",
    "    sim_returns = returns.sample(n_simulation, replace=True)\n",
    "    sim_prices = np.dot(sim_returns* assets_prices.tail(1).values.reshape(assets_prices.shape[1],),holdings)   \n",
    "    var_hist = -np.percentile(sim_prices, alpha*100) \n",
    "    return current_price[0], var_hist, sim_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current value for A is: 1089316.16\n",
      "VaR for A using Delta Normal is: 15426.97\n",
      "VaR for A using Historic Simulation is: 17065.30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "current_price, delta_var = calculate_delta_var(portfolio, daily_prices, portfolio_name='A')\n",
    "current_price, hist_var, hist_sim_prices = calculate_historic_var(portfolio, daily_prices, portfolio_name='A')\n",
    "\n",
    "print(\"The current value for A is: {:.2f}\".format(current_price))\n",
    "print(\"VaR for A using Delta Normal is: {:.2f}\".format(delta_var))\n",
    "print(\"VaR for A using Historic Simulation is: {:.2f}\\n\".format(hist_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current value for B is: 574542.41\n",
      "VaR for B using Delta Normal is: 8082.57\n",
      "VaR for B using Historic Simulation is: 12115.66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current_price, delta_var = calculate_delta_var(portfolio, daily_prices, portfolio_name='B')\n",
    "current_price, hist_var, hist_sim_prices = calculate_historic_var(portfolio, daily_prices, portfolio_name='B')\n",
    "print(\"The current value for B is: {:.2f}\".format(current_price))\n",
    "print(\"VaR for B using Delta Normal is: {:.2f}\".format(delta_var))\n",
    "print(\"VaR for B using Historic Simulation is: {:.2f}\\n\".format(hist_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current value for C is: 1387409.51\n",
      "VaR for C using Delta Normal is: 18163.29\n",
      "VaR for C using Historic Simulation is: 22187.13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current_price, delta_var = calculate_delta_var(portfolio, daily_prices, portfolio_name='C')\n",
    "current_price, hist_var, hist_sim_prices = calculate_historic_var(portfolio, daily_prices, portfolio_name='C')\n",
    "print(\"The current value for C is: {:.2f}\".format(current_price))\n",
    "print(\"VaR for C using Delta Normal is: {:.2f}\".format(delta_var))\n",
    "print(\"VaR for C using Historic Simulation is: {:.2f}\\n\".format(hist_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current value for total is: 3051268.07\n",
      "VaR for total using Delta Normal is: 38941.38\n",
      "VaR for total using Historic Simulation is: 46871.90\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/14/qnbmw8kx46x2ncgblvbvxh1m0000gn/T/ipykernel_21142/1937632565.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[vars_[i]] = p2[:, i]\n",
      "/var/folders/14/qnbmw8kx46x2ncgblvbvxh1m0000gn/T/ipykernel_21142/1937632565.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[vars_[i]] = p2[:, i]\n"
     ]
    }
   ],
   "source": [
    "current_price, delta_var = calculate_delta_var(portfolio, daily_prices, portfolio_name='All')\n",
    "current_price, hist_var, hist_sim_prices = calculate_historic_var(portfolio, daily_prices, portfolio_name='All')\n",
    "print(\"The current value for total is: {:.2f}\".format(current_price))\n",
    "print(\"VaR for total using Delta Normal is: {:.2f}\".format(delta_var))\n",
    "print(\"VaR for total using Historic Simulation is: {:.2f}\\n\".format(hist_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08e39db6518ce4d240cffb5317ee730740ab2eb9176617da045d0a992469fbee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
